{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code converts the spreadsheets into a single dataframe and creates a dictionary that tags each column with keys that identify string and/or number quality. These tags include capitalization errors, consistency in nonalphanumeric notation, misspellings, variance in numerical digits, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import libraries\n",
    "import pandas as pd\n",
    "from enchant.checker import SpellChecker ## package 'pyenchant'\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Data\n",
    "Data = pd.ExcelFile('inputData/EAR_Raw_2016.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#New variable for each spreadsheet\n",
    "table1 = pd.read_excel(Data, \"Table1_Final\")\n",
    "table2 = pd.read_excel(Data, \"Table2_Final\")\n",
    "table3 = pd.read_excel(Data, \"Table3_Final\")\n",
    "table4 = pd.read_excel(Data, \"Table4_LWS\")\n",
    "table5 = pd.read_excel(Data, \"Table5_SWS\")\n",
    "\n",
    "#Organize into list, specify key for joining\n",
    "tables = [table1, table2, table3, table4, table5]\n",
    "key = \"PWSID\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This funtion merges each spreadsheet to the first sequential based on a given key.\n",
    "#In .merge(), kwarg 'how = outer' indicates all rows are kept regardless of matching PWSID.\n",
    "def outer_join(key, tables):\n",
    "    first_table = tables[0]\n",
    "    for i in range(len(tables)):\n",
    "        if i > 0:\n",
    "            first_table = first_table.merge(tables[i], on=key, how=\"outer\")\n",
    "    return first_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Print the shapes of the spreadsheets for comparison\n",
    "for i in range(len(tables)):\n",
    "    print(\"Spreadsheet %s shape =\" %i, tables[i].shape,'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Print the shape of the newly merged dataframe.\n",
    "j_tables = outer_join(key, tables)\n",
    "print(\"Joined Spreadsheet shape =\", j_tables.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTES: Function works as expected. The number 6838 is concerning. There are 21 PWSIDs that\n",
    "# do not appear in at least one spreadsheet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tables_df = pd.DataFrame(j_tables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nonalpha(col):\n",
    "    nondict = [\"@\",\"!\",\"\\$\",\"\\(|\\)|-\",\"_\",\"\\\"\",\"\\'\",\"\\*\",\"&\",\"~+\"]\n",
    "    percarr = []\n",
    "    for n in nondict:\n",
    "        reg = re.compile(n)\n",
    "        nonalphaList = list(filter(reg.search,col))\n",
    "        percarr.append((1.0*len(nonalphaList))/len(col))\n",
    "    if np.max(percarr) > 0.01:\n",
    "        return \"{0:.2f}\".format(np.max(percarr))+\" \"+nondict[percarr.index(np.max(percarr))]\n",
    "\n",
    "def spellcheck(col):\n",
    "    chkr = SpellChecker(\"en_US\")\n",
    "    mispelledrows = []\n",
    "    for index, row in enumerate(col):\n",
    "        chkr.set_text(row)\n",
    "        errarr = []\n",
    "        for error in chkr:\n",
    "            errarr.append(error.word)\n",
    "        if len(errarr) != 0:\n",
    "            mispelledrows.append(index)\n",
    "    return mispelledrows\n",
    "\n",
    "def capital(col):\n",
    "    words = np.asarray(col)\n",
    "    nocaps = [word for word in words if word.islower()]\n",
    "    allcaps = [word for word in words if word.isupper()]\n",
    "    mixcaps = [word for word in words if not word.islower() and not word.isupper()]\n",
    "    caparr = [len(nocaps),len(allcaps),len(mixcaps)]\n",
    "    max_index = caparr.index(max(caparr))\n",
    "    caparr.remove(max(caparr))\n",
    "    \n",
    "    return [[\"No Caps\",\"Allcaps\",\"Mixed Caps\"][max_index],sum(caparr)]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def is_num(a):\n",
    "    if type(a) is int or type(a) is float:\n",
    "        return True\n",
    "    else:\n",
    "       return False\n",
    "\n",
    "def tagger(col):\n",
    "    tagdict = {}\n",
    "    cleancol = list(filter(None,col))\n",
    "    if any(isinstance(elem, str) for elem in cleancol):\n",
    "        strcol = list(map(str,cleancol))\n",
    "        tagdict[\"Capitalization, #OtherCaps\"] = capital(strcol)\n",
    "        tagdict[\"Nonalpha\"] = nonalpha(strcol)\n",
    "        tagdict[\"Misspelled Rows\"] = spellcheck(strcol)\n",
    "        if any(elem.startswith(\" \") for elem in strcol):\n",
    "            tagdict[\"Leading Space Rows\"] = np.where(list(map(lambda x : x.startswith(\" \"),strcol)))\n",
    "        if any(is_num(elem) for elem in cleancol):\n",
    "            tagdict[\"Num Rows among Strings\"] = (1.0*np.sum(list(map(lambda x : is_num(x),cleancol))))/len(cleancol)\n",
    "    else:\n",
    "        tagdict[\"Number Variance\"] = np.var(list(map(lambda x : len(str(x)),col)))\n",
    "        tagdict[\"Number Mean\"] = np.mean(list(map(lambda x : len(str(x)),col)))\n",
    "    return tagdict\n",
    "\n",
    "#Capitalization tag: What is the most common capitalization and how many rows have different caps?\n",
    "#Nonalpha tag: What is the most common nonalphanumeric character (@,parentheses,dashes,etc.) and what fraction of rows possess it?\n",
    "#Misspelled Rows tag: Which rows have misspelled words?\n",
    "#Lead Space Rows tag: Which rows have leading spaces?\n",
    "#Num Rows among Strings tag: Are there columns with cells that contain either numbers of strings? What is the ratio of number rows to string rows?\n",
    "#Number Variance: What is the digit variance of number columns?\n",
    "#Number mean: What is the digit mean of number columns?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tables_df.apply(lambda x: tagger(x), axis = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
